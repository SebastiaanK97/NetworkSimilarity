{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "         V1        V2        V3        V4        V5        V6        V7  \\\n0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9       V10  ...       V21       V22       V23       V24  \\\n0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n\n        V25       V26       V27       V28  Class  normAmount  \n0  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n1  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n2 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n3  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n4 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Class</th>\n      <th>normAmount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>0.090794</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>0</td>\n      <td>0.244964</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>-0.166974</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>0</td>\n      <td>-0.342475</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>0.207643</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>0</td>\n      <td>1.160686</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>-0.054952</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>0</td>\n      <td>0.140534</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>0.753074</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>0</td>\n      <td>-0.073403</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cc = pd.read_csv(\"data/creditcard.csv\")\n",
    "df_cc['normAmount'] = StandardScaler().fit_transform(df_cc['Amount'].values.reshape (-1,1))\n",
    "df_cc = df_cc.drop(['Time', 'Amount'], axis = 1)\n",
    "df_cc.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def data_import(d, n, output, type, drop_amount, standardise):\n",
    "\n",
    "    if (d != None) & (n != None):\n",
    "        df_node = pd.read_csv(f\"embeddings_{type}/vector_d{d}_n{n}.csv\")\n",
    "\n",
    "        lists = []\n",
    "\n",
    "        for i in range(0, len(df_node)):\n",
    "            string_list = df_node.embedding[i]\n",
    "            lists.append(json.loads(string_list))\n",
    "\n",
    "        nodes = []\n",
    "\n",
    "        for i in range(0, len(lists[0])):\n",
    "            nodes.append(f'N{i+1}')\n",
    "\n",
    "        df_node[nodes] = pd.DataFrame(lists, index= df_node.index)\n",
    "\n",
    "    if drop_amount == True:\n",
    "        df_drop = df_cc.drop(['normAmount'], axis = 1)\n",
    "    elif drop_amount == False:\n",
    "        df_drop = df_cc\n",
    "\n",
    "    if output == \"NE\":\n",
    "        df = pd.concat([df_node.drop(['nodeId', 'embedding'], axis = 1), df_cc[['Class', 'normAmount']]], axis=1)\n",
    "    elif output == \"PCA\":\n",
    "        df = df_drop\n",
    "    elif output == \"ALL\":\n",
    "        df = pd.concat([df_node.drop(['nodeId', 'embedding'], axis = 1), df_drop], axis=1)\n",
    "\n",
    "    if standardise == True:\n",
    "        df.iloc[:, :-2] = StandardScaler().fit_transform(df.iloc[:, :-2])\n",
    "    elif standardise == False:\n",
    "        df = df\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def data_preparation_classification(df):\n",
    "\n",
    "    X = df.iloc[:, df.columns != 'Class']\n",
    "    y = df.iloc[:, df.columns == 'Class']\n",
    "\n",
    "    number_records_fraud = len(df[df.Class == 1])\n",
    "\n",
    "    fraud_indices = np.array(df[df.Class==1].index)\n",
    "    normal_indices = np.array(df[df.Class==0].index)\n",
    "\n",
    "    random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False )\n",
    "    under_sample_indices = np.concatenate ([fraud_indices, random_normal_indices])\n",
    "\n",
    "    under_sample_df = df.iloc[under_sample_indices,:]\n",
    "    X_undersample = under_sample_df.iloc [:, under_sample_df.columns != 'Class']\n",
    "    y_undersample = under_sample_df.iloc [:, under_sample_df.columns == 'Class']\n",
    "\n",
    "    X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(X_undersample, y_undersample,\n",
    "                                                                                test_size=0.3, random_state=None)\n",
    "\n",
    "    LR = LogisticRegression(C=0.01, penalty='l2')\n",
    "    LR.fit(X_train_under, y_train_under.values.ravel())\n",
    "    y_pred = LR.predict(X_test_under)\n",
    "\n",
    "    output_scores = [recall_score(y_test_under, y_pred), precision_score(y_test_under, y_pred), roc_auc_score(y_test_under, y_pred)]\n",
    "\n",
    "    return output_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_temporary = data_import(d=None, n=None, output=\"PCA\", type=\"weighted\", drop_amount=False, standardise=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#iteration\n",
    "iteration = range(1, 51)\n",
    "#outcome variables\n",
    "recall = [None]\n",
    "precision = [None]\n",
    "AUC = [None]\n",
    "\n",
    "lp1, lp2, lp3, lp4 = pd.core.reshape.util.cartesian_product([iteration, recall, precision, AUC])\n",
    "bm = pd.DataFrame(dict(i=lp1, recall=lp2, precision=lp3, AUC=lp4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "for i in iteration:\n",
    "\n",
    "    bm.loc[bm[\"i\"] == i, [\"recall\", \"precision\", \"AUC\"]] = data_preparation_classification(df_temporary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "     i    recall precision       AUC\n0    1  0.888889  0.992248  0.941155\n1    2  0.839161       1.0   0.91958\n2    3  0.869863  0.976923  0.924932\n3    4  0.863014  0.984375   0.92484\n4    5  0.861111     0.992  0.927266\n5    6   0.93662  0.992537  0.965063\n6    7  0.902778  0.970149  0.938231\n7    8   0.81295  0.982609  0.900105\n8    9  0.844156  0.977444  0.911515\n9   10  0.892405  0.986014  0.938956\n10  11  0.846154   0.98374  0.916541\n11  12  0.853503  0.992593  0.923154\n12  13  0.878378       1.0  0.939189\n13  14  0.835526  0.992188  0.914291\n14  15  0.807692  0.992126  0.900275\n15  16  0.898649  0.985185  0.942568\n16  17  0.866667       1.0  0.933333\n17  18   0.84472       1.0   0.92236\n18  19  0.870748  0.984615  0.928663\n19  20  0.822222  0.991071  0.908006\n20  21  0.857143       1.0  0.928571\n21  22  0.868966  0.984375   0.92786\n22  23  0.862069  0.968992  0.917789\n23  24  0.848684  0.984733  0.917398\n24  25  0.883562       1.0  0.941781\n25  26  0.865854  0.986111  0.925351\n26  27  0.900709  0.984496  0.943903\n27  28  0.840764  0.963504  0.902397\n28  29  0.861111  0.984127  0.923977\n29  30  0.879433  0.984127  0.933265\n30  31  0.908451  0.977273  0.944485\n31  32  0.882353  0.992647   0.93768\n32  33   0.87013       1.0  0.935065\n33  34   0.88961  0.992754  0.941284\n34  35  0.891892  0.977778  0.935811\n35  36   0.86014  0.991935  0.926802\n36  37      0.86  0.992308  0.926575\n37  38   0.89726  0.984962  0.941963\n38  39  0.888112       1.0  0.944056\n39  40  0.874172  0.992481  0.933638\n40  41  0.876712  0.992248  0.935023\n41  42   0.89726  0.984962  0.941963\n42  43   0.85034       1.0   0.92517\n43  44  0.927632  0.979167  0.953399\n44  45  0.873418  0.978723  0.925839\n45  46  0.846667       1.0  0.923333\n46  47  0.871795  0.985507  0.928755\n47  48  0.874172       1.0  0.937086\n48  49  0.895425       1.0  0.947712\n49  50  0.863636  0.992537  0.928297",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>i</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.888889</td>\n      <td>0.992248</td>\n      <td>0.941155</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.839161</td>\n      <td>1.0</td>\n      <td>0.91958</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.869863</td>\n      <td>0.976923</td>\n      <td>0.924932</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.863014</td>\n      <td>0.984375</td>\n      <td>0.92484</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.861111</td>\n      <td>0.992</td>\n      <td>0.927266</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.93662</td>\n      <td>0.992537</td>\n      <td>0.965063</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.902778</td>\n      <td>0.970149</td>\n      <td>0.938231</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.81295</td>\n      <td>0.982609</td>\n      <td>0.900105</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.844156</td>\n      <td>0.977444</td>\n      <td>0.911515</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0.892405</td>\n      <td>0.986014</td>\n      <td>0.938956</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>0.846154</td>\n      <td>0.98374</td>\n      <td>0.916541</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>0.853503</td>\n      <td>0.992593</td>\n      <td>0.923154</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0.878378</td>\n      <td>1.0</td>\n      <td>0.939189</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0.835526</td>\n      <td>0.992188</td>\n      <td>0.914291</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>0.807692</td>\n      <td>0.992126</td>\n      <td>0.900275</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>0.898649</td>\n      <td>0.985185</td>\n      <td>0.942568</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>0.866667</td>\n      <td>1.0</td>\n      <td>0.933333</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>0.84472</td>\n      <td>1.0</td>\n      <td>0.92236</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>0.870748</td>\n      <td>0.984615</td>\n      <td>0.928663</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>0.822222</td>\n      <td>0.991071</td>\n      <td>0.908006</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>0.857143</td>\n      <td>1.0</td>\n      <td>0.928571</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>0.868966</td>\n      <td>0.984375</td>\n      <td>0.92786</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>0.862069</td>\n      <td>0.968992</td>\n      <td>0.917789</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>0.848684</td>\n      <td>0.984733</td>\n      <td>0.917398</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>0.883562</td>\n      <td>1.0</td>\n      <td>0.941781</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>0.865854</td>\n      <td>0.986111</td>\n      <td>0.925351</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>0.900709</td>\n      <td>0.984496</td>\n      <td>0.943903</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>0.840764</td>\n      <td>0.963504</td>\n      <td>0.902397</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>0.861111</td>\n      <td>0.984127</td>\n      <td>0.923977</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>30</td>\n      <td>0.879433</td>\n      <td>0.984127</td>\n      <td>0.933265</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>31</td>\n      <td>0.908451</td>\n      <td>0.977273</td>\n      <td>0.944485</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>32</td>\n      <td>0.882353</td>\n      <td>0.992647</td>\n      <td>0.93768</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>33</td>\n      <td>0.87013</td>\n      <td>1.0</td>\n      <td>0.935065</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>34</td>\n      <td>0.88961</td>\n      <td>0.992754</td>\n      <td>0.941284</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>35</td>\n      <td>0.891892</td>\n      <td>0.977778</td>\n      <td>0.935811</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>36</td>\n      <td>0.86014</td>\n      <td>0.991935</td>\n      <td>0.926802</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>37</td>\n      <td>0.86</td>\n      <td>0.992308</td>\n      <td>0.926575</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>38</td>\n      <td>0.89726</td>\n      <td>0.984962</td>\n      <td>0.941963</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>39</td>\n      <td>0.888112</td>\n      <td>1.0</td>\n      <td>0.944056</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>40</td>\n      <td>0.874172</td>\n      <td>0.992481</td>\n      <td>0.933638</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>41</td>\n      <td>0.876712</td>\n      <td>0.992248</td>\n      <td>0.935023</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>42</td>\n      <td>0.89726</td>\n      <td>0.984962</td>\n      <td>0.941963</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>43</td>\n      <td>0.85034</td>\n      <td>1.0</td>\n      <td>0.92517</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>44</td>\n      <td>0.927632</td>\n      <td>0.979167</td>\n      <td>0.953399</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>45</td>\n      <td>0.873418</td>\n      <td>0.978723</td>\n      <td>0.925839</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>46</td>\n      <td>0.846667</td>\n      <td>1.0</td>\n      <td>0.923333</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>47</td>\n      <td>0.871795</td>\n      <td>0.985507</td>\n      <td>0.928755</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>48</td>\n      <td>0.874172</td>\n      <td>1.0</td>\n      <td>0.937086</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>49</td>\n      <td>0.895425</td>\n      <td>1.0</td>\n      <td>0.947712</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>50</td>\n      <td>0.863636</td>\n      <td>0.992537</td>\n      <td>0.928297</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "bm.to_csv(f\"results/model/bm_LR_model.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}