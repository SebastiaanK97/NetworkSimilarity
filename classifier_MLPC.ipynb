{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "         V1        V2        V3        V4        V5        V6        V7  \\\n0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9       V10  ...       V21       V22       V23       V24  \\\n0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n\n        V25       V26       V27       V28  Class  normAmount  \n0  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n1  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n2 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n3  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n4 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Class</th>\n      <th>normAmount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>0.090794</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>0</td>\n      <td>0.244964</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>-0.166974</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>0</td>\n      <td>-0.342475</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>0.207643</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>0</td>\n      <td>1.160686</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>-0.054952</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>0</td>\n      <td>0.140534</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>0.753074</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>0</td>\n      <td>-0.073403</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cc = pd.read_csv(\"data/creditcard.csv\")\n",
    "df_cc['normAmount'] = StandardScaler().fit_transform(df_cc['Amount'].values.reshape (-1,1))\n",
    "df_cc = df_cc.drop(['Time', 'Amount'], axis = 1)\n",
    "df_cc.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def data_import(d, n, output, type, drop_amount, standardise):\n",
    "\n",
    "    if (d != None) & (n != None):\n",
    "        df_node = pd.read_csv(f\"embeddings_{type}/vector_d{d}_n{n}.csv\")\n",
    "\n",
    "        lists = []\n",
    "\n",
    "        for i in range(0, len(df_node)):\n",
    "            string_list = df_node.embedding[i]\n",
    "            lists.append(json.loads(string_list))\n",
    "\n",
    "        nodes = []\n",
    "\n",
    "        for i in range(0, len(lists[0])):\n",
    "            nodes.append(f'N{i+1}')\n",
    "\n",
    "        df_node[nodes] = pd.DataFrame(lists, index= df_node.index)\n",
    "\n",
    "    if drop_amount == True:\n",
    "        df_drop = df_cc.drop(['normAmount'], axis = 1)\n",
    "    elif drop_amount == False:\n",
    "        df_drop = df_cc\n",
    "\n",
    "    if output == \"NE\":\n",
    "        df = pd.concat([df_node.drop(['nodeId', 'embedding'], axis = 1), df_cc[['Class', 'normAmount']]], axis=1)\n",
    "    elif output == \"PCA\":\n",
    "        df = df_drop\n",
    "    elif output == \"ALL\":\n",
    "        df = pd.concat([df_node.drop(['nodeId', 'embedding'], axis = 1), df_drop], axis=1)\n",
    "\n",
    "    if standardise == True:\n",
    "        df.iloc[:, :-2] = StandardScaler().fit_transform(df.iloc[:, :-2])\n",
    "    elif standardise == False:\n",
    "        df = df\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def data_preparation_classification(df):\n",
    "\n",
    "    X = df.iloc[:, df.columns != 'Class']\n",
    "    y = df.iloc[:, df.columns == 'Class']\n",
    "\n",
    "    number_records_fraud = len(df[df.Class == 1])\n",
    "\n",
    "    fraud_indices = np.array(df[df.Class==1].index)\n",
    "    normal_indices = np.array(df[df.Class==0].index)\n",
    "\n",
    "    random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False )\n",
    "    under_sample_indices = np.concatenate ([fraud_indices, random_normal_indices])\n",
    "\n",
    "    under_sample_df = df.iloc[under_sample_indices,:]\n",
    "    X_undersample = under_sample_df.iloc [:, under_sample_df.columns != 'Class']\n",
    "    y_undersample = under_sample_df.iloc [:, under_sample_df.columns == 'Class']\n",
    "\n",
    "    X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(X_undersample, y_undersample,\n",
    "                                                                                test_size=0.3, random_state=None)\n",
    "\n",
    "    MLPC = MLPClassifier(hidden_layer_sizes=(200,), max_iter=10000)\n",
    "    MLPC.fit(X_train_under, y_train_under.values.ravel())\n",
    "    y_pred = MLPC.predict(X_test_under)\n",
    "\n",
    "    output_scores = [recall_score(y_test_under, y_pred), precision_score(y_test_under, y_pred), roc_auc_score(y_test_under, y_pred)]\n",
    "\n",
    "    return output_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_temporary = data_import(d=None, n=None, output=\"PCA\", type=\"weighted\", drop_amount=False, standardise=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#iteration\n",
    "iteration = range(1, 51)\n",
    "#outcome variables\n",
    "recall = [None]\n",
    "precision = [None]\n",
    "AUC = [None]\n",
    "\n",
    "lp1, lp2, lp3, lp4 = pd.core.reshape.util.cartesian_product([iteration, recall, precision, AUC])\n",
    "bm = pd.DataFrame(dict(i=lp1, recall=lp2, precision=lp3, AUC=lp4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "for i in iteration:\n",
    "\n",
    "    bm.loc[bm[\"i\"] == i, [\"recall\", \"precision\", \"AUC\"]] = data_preparation_classification(df_temporary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "     i    recall precision       AUC\n0    1  0.922078  0.972603  0.946954\n1    2  0.886076  0.972222  0.928545\n2    3  0.874214  0.952055  0.911559\n3    4  0.905797   0.94697  0.930747\n4    5  0.923077  0.942857  0.935395\n5    6  0.890511  0.931298  0.916954\n6    7      0.92  0.971831  0.946301\n7    8  0.942446  0.903448  0.926637\n8    9  0.908451  0.941606  0.928251\n9   10  0.877551  0.969925  0.925353\n10  11  0.905797  0.968992   0.94024\n11  12   0.93662  0.956835  0.948829\n12  13  0.946309  0.972414  0.959549\n13  14  0.890411  0.955882  0.925205\n14  15  0.910959  0.963768  0.938813\n15  16  0.955224  0.948148  0.956007\n16  17  0.927007  0.940741  0.938346\n17  18  0.865854  0.986111  0.925351\n18  19  0.933333  0.958904  0.946119\n19  20   0.90604  0.950704  0.929211\n20  21  0.913043  0.986577  0.949114\n21  22  0.943038  0.943038   0.93891\n22  23  0.948052  0.966887   0.95642\n23  24  0.891026  0.965278  0.927656\n24  25  0.936306  0.948387  0.939376\n25  26  0.930556  0.937063  0.935673\n26  27  0.891156  0.949275  0.922088\n27  28  0.939597  0.985915  0.962996\n28  29  0.928105   0.95302  0.939577\n29  30  0.920863  0.962406  0.944508\n30  31  0.918919  0.957746  0.939189\n31  32  0.886076  0.965517  0.924922\n32  33  0.916129  0.972603   0.94388\n33  34  0.931298   0.96063  0.950497\n34  35  0.931973  0.951389  0.942496\n35  36  0.913907  0.945205  0.929367\n36  37  0.900662  0.978417  0.939986\n37  38  0.871622  0.969925  0.922297\n38  39  0.935252  0.942029  0.942148\n39  40  0.956522  0.970588  0.965603\n40  41  0.894737  0.971429   0.93348\n41  42       0.9  0.964286  0.932877\n42  43  0.909091  0.948905   0.93167\n43  44  0.899281  0.961538  0.933717\n44  45  0.932432  0.951724  0.942568\n45  46  0.912162  0.978261  0.945946\n46  47  0.937931  0.971429   0.95572\n47  48  0.918919  0.985507  0.952703\n48  49  0.855172   0.96124   0.91103\n49  50  0.917241  0.970803  0.945376",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>i</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.922078</td>\n      <td>0.972603</td>\n      <td>0.946954</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.886076</td>\n      <td>0.972222</td>\n      <td>0.928545</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.874214</td>\n      <td>0.952055</td>\n      <td>0.911559</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.905797</td>\n      <td>0.94697</td>\n      <td>0.930747</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.923077</td>\n      <td>0.942857</td>\n      <td>0.935395</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.890511</td>\n      <td>0.931298</td>\n      <td>0.916954</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.92</td>\n      <td>0.971831</td>\n      <td>0.946301</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.942446</td>\n      <td>0.903448</td>\n      <td>0.926637</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.908451</td>\n      <td>0.941606</td>\n      <td>0.928251</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0.877551</td>\n      <td>0.969925</td>\n      <td>0.925353</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>0.905797</td>\n      <td>0.968992</td>\n      <td>0.94024</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>0.93662</td>\n      <td>0.956835</td>\n      <td>0.948829</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0.946309</td>\n      <td>0.972414</td>\n      <td>0.959549</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0.890411</td>\n      <td>0.955882</td>\n      <td>0.925205</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>0.910959</td>\n      <td>0.963768</td>\n      <td>0.938813</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>0.955224</td>\n      <td>0.948148</td>\n      <td>0.956007</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>0.927007</td>\n      <td>0.940741</td>\n      <td>0.938346</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>0.865854</td>\n      <td>0.986111</td>\n      <td>0.925351</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>0.933333</td>\n      <td>0.958904</td>\n      <td>0.946119</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>0.90604</td>\n      <td>0.950704</td>\n      <td>0.929211</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>0.913043</td>\n      <td>0.986577</td>\n      <td>0.949114</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>0.943038</td>\n      <td>0.943038</td>\n      <td>0.93891</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>0.948052</td>\n      <td>0.966887</td>\n      <td>0.95642</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>0.891026</td>\n      <td>0.965278</td>\n      <td>0.927656</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>0.936306</td>\n      <td>0.948387</td>\n      <td>0.939376</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>0.930556</td>\n      <td>0.937063</td>\n      <td>0.935673</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>0.891156</td>\n      <td>0.949275</td>\n      <td>0.922088</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>0.939597</td>\n      <td>0.985915</td>\n      <td>0.962996</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>0.928105</td>\n      <td>0.95302</td>\n      <td>0.939577</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>30</td>\n      <td>0.920863</td>\n      <td>0.962406</td>\n      <td>0.944508</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>31</td>\n      <td>0.918919</td>\n      <td>0.957746</td>\n      <td>0.939189</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>32</td>\n      <td>0.886076</td>\n      <td>0.965517</td>\n      <td>0.924922</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>33</td>\n      <td>0.916129</td>\n      <td>0.972603</td>\n      <td>0.94388</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>34</td>\n      <td>0.931298</td>\n      <td>0.96063</td>\n      <td>0.950497</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>35</td>\n      <td>0.931973</td>\n      <td>0.951389</td>\n      <td>0.942496</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>36</td>\n      <td>0.913907</td>\n      <td>0.945205</td>\n      <td>0.929367</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>37</td>\n      <td>0.900662</td>\n      <td>0.978417</td>\n      <td>0.939986</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>38</td>\n      <td>0.871622</td>\n      <td>0.969925</td>\n      <td>0.922297</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>39</td>\n      <td>0.935252</td>\n      <td>0.942029</td>\n      <td>0.942148</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>40</td>\n      <td>0.956522</td>\n      <td>0.970588</td>\n      <td>0.965603</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>41</td>\n      <td>0.894737</td>\n      <td>0.971429</td>\n      <td>0.93348</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>42</td>\n      <td>0.9</td>\n      <td>0.964286</td>\n      <td>0.932877</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>43</td>\n      <td>0.909091</td>\n      <td>0.948905</td>\n      <td>0.93167</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>44</td>\n      <td>0.899281</td>\n      <td>0.961538</td>\n      <td>0.933717</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>45</td>\n      <td>0.932432</td>\n      <td>0.951724</td>\n      <td>0.942568</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>46</td>\n      <td>0.912162</td>\n      <td>0.978261</td>\n      <td>0.945946</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>47</td>\n      <td>0.937931</td>\n      <td>0.971429</td>\n      <td>0.95572</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>48</td>\n      <td>0.918919</td>\n      <td>0.985507</td>\n      <td>0.952703</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>49</td>\n      <td>0.855172</td>\n      <td>0.96124</td>\n      <td>0.91103</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>50</td>\n      <td>0.917241</td>\n      <td>0.970803</td>\n      <td>0.945376</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "bm.to_csv(f\"results/model/bm_MLPC_model.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}